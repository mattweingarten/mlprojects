{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd #Pandas\n",
    "import numpy as np #Numpy\n",
    "import sklearn #Sklearn\n",
    "import math\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "#libraries needed for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Libraries needed for imputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#Libraries needed for models\n",
    "#subtasks 1 and 2\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "#subtask3\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Libraries needed for plotters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Libraries needed for scoring\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "np.set_printoptions(precision=5,suppress=True, linewidth=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "1. check_all_nan - checks if column is all NaN\n",
    "- zeroize - returns zero vector\n",
    "- get_next_val\n",
    "- get_patient_matrix - returns matrix containing patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_nan(vector):\n",
    "    checker = np.vectorize(np.isnan)\n",
    "    return np.all(checker(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize(vector):\n",
    "    for i in range(vector.size):\n",
    "        vector[i] = 0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_val(vector,index):\n",
    "    count = 0\n",
    "    for j in range(vector.size - index):\n",
    "        if(np.isnan(vector[index + j]) == False):\n",
    "            return (count,vector[index + j])\n",
    "        count += 1\n",
    "    return (count,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_matrix(raw_data,i):\n",
    "    n,w = raw_data.shape\n",
    "    return raw_data[(12 * i): (12 *(i+1))][:,3:w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation functions\n",
    "1. interp\n",
    "- nan_imputer - imputes data using sklearn InterativeImputer function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(vector):\n",
    "   if(check_all_nan(vector)):\n",
    "       return zeroize(vector)\n",
    "   prev_val = np.nan\n",
    "   for i in range(vector.size):\n",
    "        nans,next_val = get_next_val(vector, i)\n",
    "        if(np.isnan(vector[i])):\n",
    "            if(np.isnan(prev_val)):\n",
    "                vector[i] = next_val\n",
    "            elif(np.isnan(next_val)):\n",
    "                vector[i] = prev_val\n",
    "            else:\n",
    "                temp = prev_val +  (next_val - prev_val)/ (nans + 1)\n",
    "                vector[i] = temp\n",
    "                prev_val = temp\n",
    "        else:\n",
    "            prev_val = vector[i]\n",
    "   return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_imputer(nds,method):\n",
    "    \"\"\"\n",
    "    Given a dataset removes NaNs using\n",
    "    Parameters:\n",
    "    Input nds - Numpy array: dataset\n",
    "    Input method - method of imputation to use\n",
    "    Output nds_xnan - Numpy array: dataset without NaNs\n",
    "    \"\"\"\n",
    "    if method==1:#Sklearn: IterativeImputer, removes NaN considering other features\n",
    "        imp = IterativeImputer(max_iter=100, random_state=0)\n",
    "        imp.fit(nds)\n",
    "        IterativeImputer(random_state=0)\n",
    "        nds_xnan = imp.transform(nds)\n",
    "    return nds_xnan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction functions\n",
    "1. time_reduction - reduces dataset by taking mean of columns per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_reduction(nds,labels, time, method):\n",
    "    \"\"\"\n",
    "    Given a dataset containing data on consecutive hours outputs a row extracting information time features\n",
    "    Parameters:\n",
    "    Input nds - numpy dataset\n",
    "    Input labels - list labels of dataset\n",
    "    Input time - time in hours to compress data \n",
    "    Input method - method of reduction to use\n",
    "    Output nds_reduced - dataset compressed \n",
    "    \"\"\"\n",
    "    nds = pd.DataFrame(nds,columns=labels)\n",
    "    datalen = len(nds)\n",
    "    numpat = int(datalen / time) #number of patients\n",
    "    \n",
    "    if method==1:#average of values per patient\n",
    "        #Reduce by taking mean of columns for each patient\n",
    "        nds_reduced = nds.groupby('pid',sort=False,as_index=False).mean()\n",
    "    return nds_reduced.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining functions\n",
    "1. clean_set - combines time_reduction and nan_imputer functions\n",
    "- flatten_min_max_slope - reduces datasets and applies interp function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_set(nds,headers,imp_method,time_method,sequence):\n",
    "    \"\"\"\n",
    "    Given a dataset containing data on consecutive hours outputs a row extracting information time features\n",
    "    Parameters:\n",
    "    Input nds - numpy dataset\n",
    "    Input headers - list headers of dataset\n",
    "    Input imp_method - time in hours to compress data \n",
    "    Input time_method - method of reduction to use\n",
    "    Input sequence - method of reduction to use\n",
    "    Output  - dataset compressed \n",
    "    \"\"\"\n",
    "    ds_clean = nds\n",
    "    if sequence:\n",
    "        ds_clean = time_reduction(ds_clean, headers, 12,time_method)\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=headers)\n",
    "    else:\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)    \n",
    "        ds_clean = time_reduction(ds_clean, headers, 12,time_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=headers)\n",
    "    \n",
    "        \n",
    "    return ds_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_min_max_slope(raw_data):\n",
    "    n,w =  raw_data.shape\n",
    "    c = w - 3\n",
    "    means = np.nanmean(raw_data,axis=0)\n",
    "    ndiv = int(n/12)\n",
    "    res = np.zeros((ndiv,1 + c * 3))\n",
    "    temp = np.zeros((12,c))\n",
    "    for i in range(ndiv):\n",
    "        temp = get_patient_matrix(raw_data,i)\n",
    "        for j in range (c):\n",
    "            temp[:,j] = interp(temp[:,j])\n",
    "        res[i][0] = raw_data[i * 12][2]\n",
    "        for j in range (c):\n",
    "            min = np.min(temp[:,j])\n",
    "            max = np.max(temp[:,j])\n",
    "            res[i][j*3+1] = min\n",
    "            res[i][j*3+2] = max\n",
    "            res[i][j*3+3] = (max-min)/12\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions\n",
    "1. sigmoid - applies sigmoid function to input\n",
    "- map_sigmoid - applies sigmoid to dataset\n",
    "- predict_sigmoid - maps the decision function of the model to sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sigmoid(X):\n",
    "    xshape = X.shape\n",
    "    if len(xshape)==1:\n",
    "        n = xshape[0]\n",
    "        for i in range(n):\n",
    "            X[i] = sigmoid(X[i])\n",
    "    else:\n",
    "        n,m = xshape\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                X[i][j] = sigmoid(X[i][j])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sigmoid(clf,data):\n",
    "    return map_sigmoid(clf.decision_function(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks - Setup\n",
    "1. Data for subtask 1 and 2: cleaned with flatten_min_max_slope function and then scaled with sklearn: StandardScaler\n",
    "2. Data for subtask 3: cleaned with clean_set function and then scaled with sklearn: MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "## Setup datasets and scalers for all subtasks\n",
    "\n",
    "#Extracting training labels and features\n",
    "dataset_y = pd.read_csv(\"train_labels.csv\")\n",
    "dataset_x = pd.read_csv(\"train_features.csv\")\n",
    "\n",
    "#lists that contain header of dataset\n",
    "dataset_x_L = list(dataset_x)\n",
    "\n",
    "#Clean set\n",
    "cds = clean_set(dataset_x,dataset_x_L,1,1,True)\n",
    "\n",
    "#Matt dataset\n",
    "raw_data = np.genfromtxt(\"./train_features.csv\",delimiter=\",\",skip_header=1)\n",
    "mdata = flatten_min_max_slope(raw_data)\n",
    "\n",
    "#Prepare all scalers \n",
    "mmcds = MinMaxScaler()\n",
    "mmcds.fit(cds)\n",
    "\n",
    "sm = StandardScaler()\n",
    "sm.fit(mdata)\n",
    "\n",
    "#Training Features\n",
    "#Subtasks 1 and 2 \n",
    "mnds_p12 = sm.transform(mdata)\n",
    "#Subtask 3\n",
    "sds_p3 = pd.DataFrame(mmcds.transform(cds),columns=dataset_x_L)\n",
    "ds_p3 = sds_p3.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "ds_p3_L = list(ds_p3) #Headers\n",
    "nds_p3 = ds_p3.to_numpy() #to numpy\n",
    "\n",
    "#Training Labels\n",
    "#Subtask1\n",
    "dataset_y1 = dataset_y.loc[:,\"LABEL_BaseExcess\":\"LABEL_EtCO2\"] #Labels to be predicted in [0,1] range\n",
    "ds_y1_L = list(dataset_y1) #headers of labels\n",
    "ndsy1 = dataset_y1.to_numpy() #to numpy\n",
    "\n",
    "#Subtask2\n",
    "dataset_y2 = dataset_y.loc[:,\"LABEL_Sepsis\"] #Labels to be predicted in [0,1] range\n",
    "ds_y2_L = [\"LABEL_Sepsis\"] #headers of labels\n",
    "ndsy2 = dataset_y2.to_numpy() #to numpy\n",
    "\n",
    "#Subtask3\n",
    "dataset_y3 = dataset_y.loc[:,\"LABEL_RRate\":\"LABEL_Heartrate\"] #Labels to be predicted\n",
    "ds_y3_L = list(dataset_y3) #headers of labels\n",
    "ndsy3 = dataset_y3.to_numpy() #to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks Models\n",
    "1. Model for subtask 1: sklearn: OneVsRestClassifier using skleran: LinearSVC model\n",
    "2. Model for subtask 2: sklearn: LinearSVC\n",
    "3. Model for subtask 3: sklearn: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model set used for training\n",
    "#Subtask1\n",
    "lsvc_s1 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                penalty='l1',\n",
    "                                loss = 'squared_hinge',\n",
    "                                C=0.019,\n",
    "                                dual=False, \n",
    "                                tol=0.001,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )\n",
    "#Model for subtask 1: Sklearn: OneVsRestClassifier using Linear SVC\n",
    "models1 = OneVsRestClassifier(lsvc_s1)\n",
    "\n",
    "#Subtask2\n",
    "lsvc_s2 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                penalty='l2',\n",
    "                                loss = 'squared_hinge',\n",
    "                                C=0.0008,\n",
    "                                dual=False, \n",
    "                                tol=0.001,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )\n",
    "\n",
    "#Model for subtask2: Sklearn: Linear SVC\n",
    "models2 = lsvc_s2\n",
    "\n",
    "#Model for subtask3: Sklearn: Ridge\n",
    "rm_s3 = sklearn.linear_model.Ridge(alpha=0.5,\n",
    "                                      fit_intercept=True,\n",
    "                                      normalize=False, \n",
    "                                      copy_X=True,\n",
    "                                      max_iter=100000,\n",
    "                                      tol=1e-6,\n",
    "                                      solver='auto',\n",
    "                                      random_state=None\n",
    "                                     )\n",
    "models3 = MultiOutputRegressor(rm_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge(alpha=0.5, copy_X=True, fit_intercept=True,\n",
       "                                     max_iter=100000, normalize=False,\n",
       "                                     random_state=None, solver='auto',\n",
       "                                     tol=1e-06),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting models on dataset\n",
    "models1.fit(mnds_p12,ndsy1)\n",
    "models2.fit(mnds_p12,ndsy2)\n",
    "models3.fit(nds_p3,ndsy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dataset to predict\n",
    "testset_x = pd.read_csv(\"test_features.csv\")\n",
    "testset_x_L = list(testset_x)\n",
    "test_x = testset_x.to_numpy()\n",
    "\n",
    "test_raw = np.genfromtxt(\"./test_features.csv\",delimiter=\",\",skip_header=1)\n",
    "\n",
    "#cleaning data, remove NaNs and reduct time\n",
    "test12_x = flatten_min_max_slope(test_raw)\n",
    "test3_x = clean_set(testset_x,testset_x_L,1,1,True)\n",
    "\n",
    "#scale data\n",
    "test12_x = sm.transform(test12_x) #Scaled with StandardScaler\n",
    "test3_x = pd.DataFrame(mmcds.transform(test3_x),columns=dataset_x_L) #Scaled with MinMaxScaler\n",
    "\n",
    "#reduced dataset for prediction, without pid\n",
    "ctes3 = test3_x.loc[:,\"Time\":\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction using best models for each subtask\n",
    "pred1 = predict_sigmoid(models1,test12_x)\n",
    "pred2 = predict_sigmoid(models2,test12_x)\n",
    "pred3 = models3.predict(ctes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion to df\n",
    "pred1 = pd.DataFrame(pred1,columns=ds_y1_L)\n",
    "pred2 = pd.DataFrame(pred2,columns=ds_y2_L)\n",
    "pred3 = pd.DataFrame(pred3,columns=ds_y3_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707593</td>\n",
       "      <td>0.654844</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>0.985365</td>\n",
       "      <td>0.991291</td>\n",
       "      <td>0.486329</td>\n",
       "      <td>0.242553</td>\n",
       "      <td>0.337295</td>\n",
       "      <td>0.372765</td>\n",
       "      <td>0.270237</td>\n",
       "      <td>0.344756</td>\n",
       "      <td>14.091650</td>\n",
       "      <td>83.468762</td>\n",
       "      <td>98.663943</td>\n",
       "      <td>82.904071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.329964</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.398904</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>0.398920</td>\n",
       "      <td>0.320671</td>\n",
       "      <td>0.325067</td>\n",
       "      <td>0.315605</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.277493</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>18.309099</td>\n",
       "      <td>88.286604</td>\n",
       "      <td>94.984419</td>\n",
       "      <td>102.687131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10003</td>\n",
       "      <td>0.387979</td>\n",
       "      <td>0.280745</td>\n",
       "      <td>0.343495</td>\n",
       "      <td>0.345677</td>\n",
       "      <td>0.347167</td>\n",
       "      <td>0.368191</td>\n",
       "      <td>0.297728</td>\n",
       "      <td>0.490090</td>\n",
       "      <td>0.285779</td>\n",
       "      <td>0.287705</td>\n",
       "      <td>0.281241</td>\n",
       "      <td>18.832443</td>\n",
       "      <td>81.398159</td>\n",
       "      <td>97.753127</td>\n",
       "      <td>92.538797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10004</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>0.286903</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.410492</td>\n",
       "      <td>0.405745</td>\n",
       "      <td>0.298992</td>\n",
       "      <td>0.316362</td>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.284264</td>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.284447</td>\n",
       "      <td>16.587392</td>\n",
       "      <td>72.373648</td>\n",
       "      <td>95.836593</td>\n",
       "      <td>88.134649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10005</td>\n",
       "      <td>0.339288</td>\n",
       "      <td>0.274910</td>\n",
       "      <td>0.297833</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>0.300466</td>\n",
       "      <td>0.305847</td>\n",
       "      <td>0.286129</td>\n",
       "      <td>0.313274</td>\n",
       "      <td>0.269874</td>\n",
       "      <td>0.231511</td>\n",
       "      <td>0.292123</td>\n",
       "      <td>19.357464</td>\n",
       "      <td>74.696847</td>\n",
       "      <td>96.005844</td>\n",
       "      <td>61.534041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12659</td>\n",
       "      <td>9989</td>\n",
       "      <td>0.484036</td>\n",
       "      <td>0.282942</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>0.356410</td>\n",
       "      <td>0.354223</td>\n",
       "      <td>0.418644</td>\n",
       "      <td>0.232480</td>\n",
       "      <td>0.363094</td>\n",
       "      <td>0.272366</td>\n",
       "      <td>0.227755</td>\n",
       "      <td>0.333432</td>\n",
       "      <td>19.758554</td>\n",
       "      <td>80.031043</td>\n",
       "      <td>95.762265</td>\n",
       "      <td>103.046655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12660</td>\n",
       "      <td>9991</td>\n",
       "      <td>0.515473</td>\n",
       "      <td>0.329618</td>\n",
       "      <td>0.376097</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>0.359779</td>\n",
       "      <td>0.407493</td>\n",
       "      <td>0.256220</td>\n",
       "      <td>0.250685</td>\n",
       "      <td>0.266227</td>\n",
       "      <td>0.295365</td>\n",
       "      <td>0.321581</td>\n",
       "      <td>18.230689</td>\n",
       "      <td>95.374560</td>\n",
       "      <td>98.778412</td>\n",
       "      <td>74.528911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12661</td>\n",
       "      <td>9992</td>\n",
       "      <td>0.507762</td>\n",
       "      <td>0.289909</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>0.320365</td>\n",
       "      <td>0.323363</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.250529</td>\n",
       "      <td>0.517562</td>\n",
       "      <td>0.275168</td>\n",
       "      <td>0.262315</td>\n",
       "      <td>0.291101</td>\n",
       "      <td>18.738353</td>\n",
       "      <td>69.116506</td>\n",
       "      <td>97.348286</td>\n",
       "      <td>84.155034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12662</td>\n",
       "      <td>9994</td>\n",
       "      <td>0.930942</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.698526</td>\n",
       "      <td>0.739675</td>\n",
       "      <td>0.789949</td>\n",
       "      <td>0.889366</td>\n",
       "      <td>0.197899</td>\n",
       "      <td>0.791365</td>\n",
       "      <td>0.313319</td>\n",
       "      <td>0.240242</td>\n",
       "      <td>0.422001</td>\n",
       "      <td>15.993554</td>\n",
       "      <td>86.583641</td>\n",
       "      <td>98.477000</td>\n",
       "      <td>96.417445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12663</td>\n",
       "      <td>9997</td>\n",
       "      <td>0.648137</td>\n",
       "      <td>0.271480</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.314275</td>\n",
       "      <td>0.318412</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>0.264845</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>0.266487</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.313529</td>\n",
       "      <td>18.180985</td>\n",
       "      <td>77.495358</td>\n",
       "      <td>98.221202</td>\n",
       "      <td>85.896028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.707593          0.654844   0.993288   \n",
       "1      10001          0.329964          0.289032   0.398904   \n",
       "2      10003          0.387979          0.280745   0.343495   \n",
       "3      10004          0.263019          0.286903   0.410673   \n",
       "4      10005          0.339288          0.274910   0.297833   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989          0.484036          0.282942   0.362074   \n",
       "12660   9991          0.515473          0.329618   0.376097   \n",
       "12661   9992          0.507762          0.289909   0.325219   \n",
       "12662   9994          0.930942          0.569146   0.698526   \n",
       "12663   9997          0.648137          0.271480   0.320050   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.985365               0.991291       0.486329   \n",
       "1                0.398247               0.398920       0.320671   \n",
       "2                0.345677               0.347167       0.368191   \n",
       "3                0.410492               0.405745       0.298992   \n",
       "4                0.294815               0.300466       0.305847   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.356410               0.354223       0.418644   \n",
       "12660            0.355090               0.359779       0.407493   \n",
       "12661            0.320365               0.323363       0.366714   \n",
       "12662            0.739675               0.789949       0.889366   \n",
       "12663            0.314275               0.318412       0.397639   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.242553    0.337295                0.372765     0.270237   \n",
       "1             0.325067    0.315605                0.279186     0.277493   \n",
       "2             0.297728    0.490090                0.285779     0.287705   \n",
       "3             0.316362    0.299407                0.284264     0.290991   \n",
       "4             0.286129    0.313274                0.269874     0.231511   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.232480    0.363094                0.272366     0.227755   \n",
       "12660         0.256220    0.250685                0.266227     0.295365   \n",
       "12661         0.250529    0.517562                0.275168     0.262315   \n",
       "12662         0.197899    0.791365                0.313319     0.240242   \n",
       "12663         0.264845    0.348192                0.266487     0.238938   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0          0.344756    14.091650   83.468762   98.663943        82.904071  \n",
       "1          0.289146    18.309099   88.286604   94.984419       102.687131  \n",
       "2          0.281241    18.832443   81.398159   97.753127        92.538797  \n",
       "3          0.284447    16.587392   72.373648   95.836593        88.134649  \n",
       "4          0.292123    19.357464   74.696847   96.005844        61.534041  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659      0.333432    19.758554   80.031043   95.762265       103.046655  \n",
       "12660      0.321581    18.230689   95.374560   98.778412        74.528911  \n",
       "12661      0.291101    18.738353   69.116506   97.348286        84.155034  \n",
       "12662      0.422001    15.993554   86.583641   98.477000        96.417445  \n",
       "12663      0.313529    18.180985   77.495358   98.221202        85.896028  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the pids and assemble final prediction\n",
    "pids = time_reduction(testset_x,list(testset_x),12,1)\n",
    "pd.DataFrame(pids)\n",
    "pids = pd.DataFrame(pids[:,0],columns=['pid'])\n",
    "pred = pd.concat([pids.astype(int),pred1,pred2, pred3], axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions into one dataframe\n",
    "#output, 3 digit floats\n",
    "pred.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check format\n",
    "df_submission = pd.read_csv('prediction.zip')\n",
    "df_sample = pd.read_csv('sample.zip')\n",
    "df_submission.shape == df_sample.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
