{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "Current considerations:\n",
    "1. Reducing through evolution system -> bad, maybe different function?\n",
    "3. For subtask 3 the best actual model is the multitask lasso with cross validation, but is slow, \n",
    "   Ridge is fast and yields good results on training set, \n",
    "   Neuralnet is between the two\n",
    "\n",
    "\n",
    "To Matt: changed something in the other subtasks and they now perform considerably worse or might not even working.\n",
    "\n",
    "I marked the sections with \"needed\" where there is coded needed for running the subtask3. \n",
    "\n",
    "It should output the predictions for subtask 3 in pandas dataframe format. I used RidgeCV as it is relatively fast and produces good results on the training set. The best so far is using MultiTaskLassoCV but is considerably slower and the difference in results is not that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed libraries\n",
    "import pandas as pd #Pandas\n",
    "import numpy as np #Numpy\n",
    "import sklearn #Sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#libraries needed for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Libraries needed for imputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#Libraries needed for models\n",
    "#subtasks 1 and 2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#subtask3\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Libraries needed for plotters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Libraries needed for scoring\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation functions - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_imputer(nds,method):\n",
    "    \"\"\"\n",
    "    Given a dataset removes NaNs using\n",
    "    Parameters:\n",
    "    Input nds - Numpy array: dataset\n",
    "    Input method - method of imputation to use\n",
    "    Output nds_xnan - Numpy array: dataset without NaNs\n",
    "    \"\"\"\n",
    "    if method==1:#Sklearn: IterativeImputer, removes NaN considering other features\n",
    "        imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "        imp.fit(nds)\n",
    "        IterativeImputer(random_state=0)\n",
    "        nds_xnan = imp.transform(nds)\n",
    "    return nds_xnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_reduction(nds,labels, time, method):\n",
    "    \"\"\"\n",
    "    Given a dataset containing data on consecutive hours outputs a row extracting information time features\n",
    "    Parameters:\n",
    "    Input nds - numpy dataset\n",
    "    Input labels - list labels of dataset\n",
    "    Input time - time in hours to compress data \n",
    "    Input method - method of reduction to use\n",
    "    Output nds_reduced - dataset compressed \n",
    "    \"\"\"\n",
    "    nds = pd.DataFrame(nds,columns=labels)\n",
    "    datalen = len(nds)\n",
    "    numpatients = datalen / time #number of patients\n",
    "    \n",
    "    if method==1:#average of values per patient\n",
    "        #Reduce by taking mean of columns for each patient\n",
    "        nds_reduced = nds.groupby('pid',sort=False,as_index=False).mean()\n",
    "        \n",
    "    elif method==2:#scoring method based on evolution of patient during stay\n",
    "        dss = np.array_split(nds,datalen,axis=0) #dataset split for each patient  \n",
    "        nds_reduced = []\n",
    "        flagr=True\n",
    "        for k in range(datalen):#for each patient\n",
    "            patient = dss[k]#select patient\n",
    "            npat = patient.to_numpy()\n",
    "            r_pat = []\n",
    "            for i in range (np.size(npat,1)):#for each label\n",
    "                cur_col = npat[:,i]\n",
    "                temp=0\n",
    "                ev = 0\n",
    "                flagn = True\n",
    "                for j in range(np.size(cur_col)):#for each row\n",
    "                    this=cur_col[j]\n",
    "                    if ~(np.isnan(this)):\n",
    "                        ev = ev + (this-temp)*(j+1) #evolution increasing on time\n",
    "                        temp=this\n",
    "                        flagn= False\n",
    "                if flagn:#if row is all NaN\n",
    "                    r_pat = np.append(r_pat,np.NaN)#insert NaN\n",
    "                else:#else\n",
    "                    r_pat = np.append(r_pat,ev)#insert evolution\n",
    "            if flagr:#if reduced set is empty\n",
    "                nds_reduced = np.append(nds_reduced,r_pat)#insert patient\n",
    "                flagr=False\n",
    "            else:#if at least one patient has been added\n",
    "                nds_reduced = np.vstack((nds_reduced, r_pat))#insert patient as row\n",
    "        #Transform to pandas for compatibility\n",
    "        nds_reduced=pd.DataFrame(nds_reduced,columns=labels)\n",
    "    #Reduce considering patient evolution during stay \n",
    "    return nds_reduced.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_set(nds,labels,imp_method,time_method,sequence):\n",
    "    ds_clean = nds\n",
    "    if sequence:\n",
    "        ds_clean = time_reduction(ds_clean, labels, 12,time_method)\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=labels)\n",
    "    else:\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)    \n",
    "        ds_clean = time_reduction(ds_clean, labels, 12,time_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=labels)\n",
    "    \n",
    "        \n",
    "    return ds_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choosing functions - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fold_10(nds, f_nr, task):\n",
    "    \"\"\"\n",
    "    Given a dataset, outputs two subsets: training set and test set. Test sets is given by the f_nr-th partition of the dataset,\n",
    "    meanwhile the training set is the remaining of the dataset\n",
    "    Parameters:\n",
    "    Input ds - numpy dataset to partition\n",
    "    Input f_nr - number of the fold that will be the test set 1-10\n",
    "    Output (testset, trainingset) - tuple containing the test set and training set\n",
    "    \"\"\"\n",
    "    dss = np.array_split(nds,10,axis=0) #dataset split\n",
    "    testset = dss[f_nr] #test set\n",
    "    if task==2:\n",
    "        trainingset = np.hstack(np.delete(dss, f_nr, 0)) #training set \n",
    "    else:\n",
    "        trainingset = np.vstack(np.delete(dss, f_nr, 0)) #training set\n",
    "    return (testset, trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold10_predict(models, ndsx, ndsy, ndsy_L, task):\n",
    "    ###Performing 10-fold Cross Validation for each Model\n",
    "    mlen = len(models) #Number of models\n",
    "    nscores = np.zeros((mlen,10)) #score of each fold\n",
    "    for j in range(10):\n",
    "        #Creating test set and training set from data set \n",
    "        if task==2:\n",
    "            (tes_x, trs_x) = data_fold_10(ndsx, j, task-1)\n",
    "            (tes_y, trs_y) = data_fold_10(ndsy, j, task)\n",
    "        else:\n",
    "            (tes_x, trs_x) = data_fold_10(ndsx, j, task)\n",
    "            (tes_y, trs_y) = data_fold_10(ndsy, j, task)\n",
    "\n",
    "        #Perform fitting and predicting for each model\n",
    "        for i in range(mlen):\n",
    "            models[i].fit(trs_x,trs_y)\n",
    "            if task==3:#if task is third we use predict\n",
    "                tes_yp = models[i].predict(tes_x)\n",
    "\n",
    "                #Transform into DataFrame for scoring\n",
    "                df_y = pd.DataFrame(tes_y, columns=ndsy_L)\n",
    "                df_yp = pd.DataFrame(tes_yp, columns=ndsy_L)\n",
    "                nscores[i,j] = scores(df_y,df_yp, task)\n",
    "            else:#else use predict_proba\n",
    "                tes_yp = models[i].predict_proba(tes_x)\n",
    "\n",
    "                #Transform into DataFrame for scoring\n",
    "                df_y = pd.DataFrame(tes_y, columns=ndsy_L)\n",
    "                if task==2:\n",
    "                    df_yp = pd.DataFrame(tes_yp[:,0], columns=ndsy_L)\n",
    "                else:\n",
    "                    df_yp = pd.DataFrame(tes_yp, columns=ndsy_L)\n",
    "                nscores[i,j] = scores(df_y,df_yp, task)\n",
    "    return nscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(tes_y, tes_yp, task):\n",
    "    if task==3:\n",
    "        VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "        score = np.mean([0.5 + 0.5 * np.maximum(0, metrics.r2_score(tes_y[entry], tes_yp[entry])) for entry in VITALS])\n",
    "    elif task==2:\n",
    "        score = metrics.roc_auc_score(tes_y['LABEL_Sepsis'], tes_yp['LABEL_Sepsis'])\n",
    "    else:\n",
    "        TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "        score = np.mean([metrics.roc_auc_score(tes_y[entry], tes_yp[entry]) for entry in TESTS])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data needed for all subtasks\n",
    "#Extracting training labels\n",
    "dataset_y = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "#Extracting training feature\n",
    "dataset_x = pd.read_csv(\"train_features.csv\")\n",
    "\n",
    "#lists that contain labels of dataset\n",
    "dataset_x_L = list(dataset_x) \n",
    "\n",
    "#Standard Scaler of dataset \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset_x)\n",
    "scaled_data = scaler.transform(dataset_x)\n",
    "scaled_data = pd.DataFrame(scaled_data,columns=dataset_x_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>PTT</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Alkalinephos</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Bilirubin_direct</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Heartrate</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>ABPs</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.725092</td>\n",
       "      <td>-0.851213</td>\n",
       "      <td>-1.706426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.558968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.973706</td>\n",
       "      <td>-0.929341</td>\n",
       "      <td>0.116246</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.308314</td>\n",
       "      <td>-1.158184</td>\n",
       "      <td>0.537177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.843444</td>\n",
       "      <td>-0.500542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.725092</td>\n",
       "      <td>-0.639173</td>\n",
       "      <td>-1.706426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.973706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113008</td>\n",
       "      <td>-0.500542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.725092</td>\n",
       "      <td>-0.427133</td>\n",
       "      <td>-1.706426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.973706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.531494</td>\n",
       "      <td>0.037220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.725092</td>\n",
       "      <td>-0.215093</td>\n",
       "      <td>-1.706426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.789295</td>\n",
       "      <td>0.037220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.725092</td>\n",
       "      <td>-0.003053</td>\n",
       "      <td>-1.706426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.539445</td>\n",
       "      <td>-0.199642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.961162</td>\n",
       "      <td>0.574982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227935</td>\n",
       "      <td>-0.632639</td>\n",
       "      <td>0.208987</td>\n",
       "      <td>1.393535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.256321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.531494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227936</td>\n",
       "      <td>-0.632639</td>\n",
       "      <td>0.421027</td>\n",
       "      <td>1.393535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227937</td>\n",
       "      <td>-0.632639</td>\n",
       "      <td>0.633067</td>\n",
       "      <td>1.393535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.973706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.256321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227938</td>\n",
       "      <td>-0.632639</td>\n",
       "      <td>0.845107</td>\n",
       "      <td>1.393535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.206384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.049060</td>\n",
       "      <td>-0.539713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227939</td>\n",
       "      <td>-0.632639</td>\n",
       "      <td>1.057147</td>\n",
       "      <td>1.393535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.312999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227940 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pid      Time       Age  EtCO2  PTT       BUN  Lactate      Temp  \\\n",
       "0      -1.725092 -0.851213 -1.706426    NaN  NaN -0.558968      NaN -0.973706   \n",
       "1      -1.725092 -0.639173 -1.706426    NaN  NaN       NaN      NaN -0.973706   \n",
       "2      -1.725092 -0.427133 -1.706426    NaN  NaN       NaN      NaN -0.973706   \n",
       "3      -1.725092 -0.215093 -1.706426    NaN  NaN       NaN      NaN  0.168959   \n",
       "4      -1.725092 -0.003053 -1.706426    NaN  NaN       NaN      NaN       NaN   \n",
       "...          ...       ...       ...    ...  ...       ...      ...       ...   \n",
       "227935 -0.632639  0.208987  1.393535    NaN  NaN       NaN      NaN       NaN   \n",
       "227936 -0.632639  0.421027  1.393535    NaN  NaN       NaN      NaN       NaN   \n",
       "227937 -0.632639  0.633067  1.393535    NaN  NaN       NaN      NaN -0.973706   \n",
       "227938 -0.632639  0.845107  1.393535    NaN  NaN       NaN      NaN       NaN   \n",
       "227939 -0.632639  1.057147  1.393535    NaN  NaN       NaN      NaN       NaN   \n",
       "\n",
       "             Hgb      HCO3  ...  Alkalinephos      SpO2  Bilirubin_direct  \\\n",
       "0      -0.929341  0.116246  ...           NaN  0.838622               NaN   \n",
       "1            NaN       NaN  ...           NaN  0.838622               NaN   \n",
       "2            NaN       NaN  ...           NaN  0.838622               NaN   \n",
       "3            NaN       NaN  ...           NaN  0.838622               NaN   \n",
       "4            NaN       NaN  ...           NaN  0.838622               NaN   \n",
       "...          ...       ...  ...           ...       ...               ...   \n",
       "227935       NaN       NaN  ...           NaN       NaN               NaN   \n",
       "227936       NaN       NaN  ...           NaN       NaN               NaN   \n",
       "227937       NaN       NaN  ...           NaN  0.120793               NaN   \n",
       "227938 -0.206384       NaN  ...           NaN  0.120793               NaN   \n",
       "227939       NaN       NaN  ...           NaN       NaN               NaN   \n",
       "\n",
       "        Chloride       Hct  Heartrate  Bilirubin_total  TroponinI      ABPs  \\\n",
       "0       1.308314 -1.158184   0.537177              NaN        NaN  0.843444   \n",
       "1            NaN       NaN   0.820569              NaN        NaN  0.113008   \n",
       "2            NaN       NaN   0.423820              NaN        NaN -0.531494   \n",
       "3            NaN       NaN   0.197107              NaN        NaN -0.789295   \n",
       "4            NaN -1.539445  -0.199642              NaN        NaN -0.961162   \n",
       "...          ...       ...        ...              ...        ...       ...   \n",
       "227935       NaN       NaN  -0.256321              NaN        NaN -0.531494   \n",
       "227936       NaN       NaN  -0.086286              NaN        NaN  0.027074   \n",
       "227937       NaN       NaN  -0.256321              NaN        NaN  0.671577   \n",
       "227938       NaN -0.049060  -0.539713              NaN        NaN  0.113008   \n",
       "227939       NaN       NaN  -0.312999              NaN        NaN  0.241908   \n",
       "\n",
       "              pH  \n",
       "0      -0.500542  \n",
       "1      -0.500542  \n",
       "2       0.037220  \n",
       "3       0.037220  \n",
       "4       0.574982  \n",
       "...          ...  \n",
       "227935       NaN  \n",
       "227936       NaN  \n",
       "227937       NaN  \n",
       "227938       NaN  \n",
       "227939       NaN  \n",
       "\n",
       "[227940 rows x 37 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask1 training models - not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model set used for training\n",
    "svcms = SVC(kernel='sigmoid', \n",
    "            decision_function_shape='ovr', \n",
    "            gamma='auto', \n",
    "            probability=True, \n",
    "            max_iter=1000)\n",
    "models1 = []\n",
    "#1 - Sklearn: OnveVsRestClassifier using svcms\n",
    "models1 = np.append(models1,OneVsRestClassifier(svcms))\n",
    "#2 - Sklearn: OneVsOneClassifier using svcms\n",
    "models1 = np.append(models1,OneVsOneClassifier(svcms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning dataset in order to remove NaNs and reduce dimensionality\n",
    "cs1 = clean_set(scaled_data,dataset_x_L,1,1,True)\n",
    "\n",
    "##Division for the prediction, probabilities divided from the real values\n",
    "dataset_y1 = dataset_y.loc[:,\"LABEL_BaseExcess\":\"LABEL_EtCO2\"] #Labels to be predicted in [0,1] range\n",
    "ds_p1 = cs1.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "\n",
    "#labels of datasets\n",
    "ds_y1_L = list(dataset_y1)\n",
    "ds_p1_L = list(ds_p1)\n",
    "\n",
    "#transform into numpy\n",
    "ndsy1 = dataset_y1.to_numpy()\n",
    "nds_p1 = ds_p1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Predictions\n",
    "s1 = fold10_predict(models1,nds_p1,ndsy1,ds_y1_L,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.average(s1,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask2 - training models - not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model list used for predictions\n",
    "models2 = []\n",
    "#0 - Sklearn: SVC \n",
    "models2 = np.append(models2,SVC(kernel='sigmoid',\n",
    "                                gamma='auto',\n",
    "                                probability=True,\n",
    "                                max_iter=1000))\n",
    "#1 - Sklearn: SVR\n",
    "#models2 = np.append(models2,SVR(kernel='sigmoid',\n",
    "#                                gamma='auto',\n",
    "#                                max_iter=1000))\n",
    "#from sklearn.svm import LinearSVC\n",
    "#models2 = np.append(models2,LinearSVC(random_state=0, tol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing dataset used for training\n",
    "#Clean dataset:\n",
    "cs2 = clean_set(scaled_data,dataset_x_L,1,1,True)\n",
    "\n",
    "##Division for the prediction, probabilities divided from the real values\n",
    "dataset_y2 = dataset_y.loc[:,\"LABEL_Sepsis\"] #Labels to be predicted in [0,1] range\n",
    "ds_p2 = cs2.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "\n",
    "#labels of datasets\n",
    "ds_y2_L = [\"LABEL_Sepsis\"]\n",
    "ds_p2_L = list(ds_p2)\n",
    "\n",
    "#transform into numpy\n",
    "ndsy2 = dataset_y2.to_numpy()\n",
    "nds_p2 = ds_p2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "s2 = fold10_predict(models2,nds_p2,ndsy2,ds_y2_L,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.average(s2,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask3 - training models - needed\n",
    "I included only ridge as it is relatively fast and produces ~0.745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model set used for training\n",
    "models3 = []\n",
    "#0 - Sklearn: Ridge regression function with alpha 1\n",
    "models3 = np.append(models3, linear_model.RidgeCV(alphas=[10*a for a in range(1,10)])) \n",
    "#1 - Sklearn: Multi Task Lasso Cross Validation on alphas\n",
    "#models3 = np.append(models3,linear_model.MultiTaskLassoCV(cv=10,\n",
    "#                                                          alphas=[10**a for a in range(-1,10)],\n",
    "#                                                          fit_intercept=False,\n",
    "#                                                          max_iter=1000))\n",
    "#2 Sklearn: Multitask Elastic Net with Cross Validation\n",
    "#models3 = np.append(models3,linear_model.MultiTaskElasticNetCV(cv=10,random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing datasets to feed models\n",
    "##clean dataset using\n",
    "# scaled_data: dataset_x scaled through StandardScaler\n",
    "# dataset_x_L: dataset labels\n",
    "# imp method: 1 - impute with IterativeImputer\n",
    "# time method: 1 - reduce with average\n",
    "# sequence: True - first reduce then converge\n",
    "cs3 = clean_set(scaled_data,dataset_x_L,1,1,True)\n",
    "\n",
    "##Division for the prediction, probabilities divided from the real values\n",
    "dataset_y3 = dataset_y.loc[:,\"LABEL_RRate\":\"LABEL_Heartrate\"] #Real valued labels\n",
    "ds_p3 = cs3.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "\n",
    "#labels of datasets\n",
    "ds_y3_L = list(dataset_y3)\n",
    "ds_p3_L = list(ds_p3)\n",
    "\n",
    "#transform into numpy\n",
    "ndsy3 = dataset_y3.to_numpy()\n",
    "nds_p3 = ds_p3.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "s3 = fold10_predict(models3, nds_p3, ndsy3, ds_y3_L, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.748734</td>\n",
       "      <td>0.746099</td>\n",
       "      <td>0.74074</td>\n",
       "      <td>0.74454</td>\n",
       "      <td>0.732383</td>\n",
       "      <td>0.767828</td>\n",
       "      <td>0.743956</td>\n",
       "      <td>0.732851</td>\n",
       "      <td>0.749092</td>\n",
       "      <td>0.755045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2        3         4         5         6  \\\n",
       "0  0.748734  0.746099  0.74074  0.74454  0.732383  0.767828  0.743956   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.732851  0.749092  0.755045  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.746127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.746127"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.average(s3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_s1 = np.average(s1)\n",
    "#avg_s2 = np.average(s2)\n",
    "#avg_s3 = np.average(s3[1])\n",
    "#np.mean([avg_s1,avg_s2,avg_s3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset predicition - subtask3 - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#This outputs the predictions for subtask3, in pandas format\n",
    "\n",
    "#extract dataset to predict\n",
    "testset_x = pd.read_csv(\"test_features.csv\")\n",
    "testset_x_L = list(testset_x)\n",
    "test_x = testset_x.to_numpy()\n",
    "\n",
    "#Standard Scaler of dataset \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(testset_x)\n",
    "scaled_test = scaler.transform(testset_x)\n",
    "scaled_test = pd.DataFrame(scaled_test,columns=dataset_x_L)\n",
    "\n",
    "#cleaning data\n",
    "test3_x = clean_set(scaled_test,testset_x_L,1,1,True)\n",
    "\n",
    "ctes3 = test3_x.loc[:,\"Time\":\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3 = models3[0] #0 is ridge, fast but worse performing\n",
    "pred3 = best_3.predict(ctes3)\n",
    "pred3 = pd.DataFrame(pred3,columns=ds_y3_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14.067502</td>\n",
       "      <td>82.084110</td>\n",
       "      <td>98.513927</td>\n",
       "      <td>83.381661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18.255210</td>\n",
       "      <td>88.805621</td>\n",
       "      <td>94.957384</td>\n",
       "      <td>102.886702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18.769762</td>\n",
       "      <td>83.807880</td>\n",
       "      <td>97.869078</td>\n",
       "      <td>91.823855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.516004</td>\n",
       "      <td>72.584750</td>\n",
       "      <td>95.821337</td>\n",
       "      <td>88.142008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19.359560</td>\n",
       "      <td>75.186645</td>\n",
       "      <td>96.004542</td>\n",
       "      <td>61.304297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12659</td>\n",
       "      <td>19.666170</td>\n",
       "      <td>80.607350</td>\n",
       "      <td>95.685558</td>\n",
       "      <td>103.118070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12660</td>\n",
       "      <td>18.381966</td>\n",
       "      <td>93.726081</td>\n",
       "      <td>98.695124</td>\n",
       "      <td>75.389952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12661</td>\n",
       "      <td>18.685788</td>\n",
       "      <td>70.779083</td>\n",
       "      <td>97.407136</td>\n",
       "      <td>83.841422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12662</td>\n",
       "      <td>16.064031</td>\n",
       "      <td>86.138289</td>\n",
       "      <td>98.432283</td>\n",
       "      <td>97.656868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12663</td>\n",
       "      <td>18.184284</td>\n",
       "      <td>75.708106</td>\n",
       "      <td>98.154968</td>\n",
       "      <td>86.667485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate\n",
       "0        14.067502   82.084110   98.513927        83.381661\n",
       "1        18.255210   88.805621   94.957384       102.886702\n",
       "2        18.769762   83.807880   97.869078        91.823855\n",
       "3        16.516004   72.584750   95.821337        88.142008\n",
       "4        19.359560   75.186645   96.004542        61.304297\n",
       "...            ...         ...         ...              ...\n",
       "12659    19.666170   80.607350   95.685558       103.118070\n",
       "12660    18.381966   93.726081   98.695124        75.389952\n",
       "12661    18.685788   70.779083   97.407136        83.841422\n",
       "12662    16.064031   86.138289   98.432283        97.656868\n",
       "12663    18.184284   75.708106   98.154968        86.667485\n",
       "\n",
       "[12664 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset prediction not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy code to combine three results\n",
    "best_1 = models1[0]#Dummy\n",
    "best_2 = models2[0]#Dummy\n",
    "best_3 = models3[1]#Dummy\n",
    "\n",
    "#extract dataset to predict\n",
    "testset_x = pd.read_csv(\"test_features.csv\")\n",
    "testset_x_L = list(testset_x)\n",
    "test_x = testset_x.to_numpy()\n",
    "#cleaning data\n",
    "test1_x = clean_set(test_x,testset_x_L,1,1,True)\n",
    "test2_x = clean_set(test_x,testset_x_L,1,1,True)\n",
    "test3_x = clean_set(test_x,testset_x_L,1,1,True)\n",
    "\n",
    "#reduced dataset for prediction, without pid\n",
    "ctes1 = test1_x.loc[:,\"Time\":\"pH\"] \n",
    "ctes2 = test2_x.loc[:,\"Time\":\"pH\"]\n",
    "ctes3 = test3_x.loc[:,\"Time\":\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction using best models for each subtask\n",
    "pred1 = best_1.predict(ctes1)\n",
    "pred2 = best_2.predict(ctes2)\n",
    "pred3 = best_3.predict(ctes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions into one dataframe)\n",
    "#output, 3 digit floats\n",
    "#pred.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
