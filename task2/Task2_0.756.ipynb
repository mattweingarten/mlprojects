{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2\n",
    "Current considerations:\n",
    "1. Current public score ~0.756 HardBaseline : 0.772478169274\n",
    "- Experiment with different parametrizations and models (currently only one per subtask)\n",
    "- Experiment with preprocessing (maybe I'll try to use PCA and see if it can make a difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current scores for subtask 1, 2 and 3:\n",
      "[0.79939] [0.70877] [0.74617]\n",
      "Average score:\n",
      "0.7514460305868481\n",
      "Overall improvement needed (per subtask)\n",
      "0.06309641606145577\n"
     ]
    }
   ],
   "source": [
    "print(\"Current scores for subtask 1, 2 and 3:\")\n",
    "print(avg_s1,avg_s2,avg_s3)\n",
    "\n",
    "print(\"Average score:\")\n",
    "sub_avg =np.average([avg_s1, avg_s2, avg_s3])\n",
    "print(sub_avg)\n",
    "\n",
    "print(\"Overall improvement needed (per subtask)\")\n",
    "print((0.772478169274 - sub_avg)*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries - needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed libraries\n",
    "import pandas as pd #Pandas\n",
    "import numpy as np #Numpy\n",
    "import sklearn #Sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "import math\n",
    "\n",
    "#libraries needed for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Libraries needed for imputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#Libraries needed for models\n",
    "#subtasks 1 and 2\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "#subtask3\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Libraries needed for plotters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Libraries needed for scoring\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "np.set_printoptions(precision=5,suppress=True, linewidth=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation functions - needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "1. check_all_nan \n",
    "- zeroize\n",
    "- scale\n",
    "- get_next_val\n",
    "- patient_pca\n",
    "- get_patient_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_nan(vector):\n",
    "    checker = np.vectorize(np.isnan)\n",
    "    return np.all(checker(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize(vector):\n",
    "    for i in range(vector.size):\n",
    "        vector[i] = 0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_val(vector,index):\n",
    "    count = 0\n",
    "    for j in range(vector.size - index):\n",
    "        if(np.isnan(vector[index + j]) == False):\n",
    "            return (count,vector[index + j])\n",
    "        count += 1\n",
    "    return (count,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_pca(data,c):\n",
    "    pca = PCA(n_components=c).fit(data)\n",
    "    return np.reshape(pca.components_,(pca.components_.size,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_matrix(raw_data,i):\n",
    "    n,w = raw_data.shape\n",
    "    return raw_data[(12 * i): (12 *(i+1))][:,3:w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation functions\n",
    "1. interp\n",
    "- nan_imputer - imputes data using sklearn InterativeImputer function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(vector):\n",
    "   if(check_all_nan(vector)):\n",
    "       return zeroize(vector)\n",
    "   prev_val = np.nan\n",
    "   for i in range(vector.size):\n",
    "        nans,next_val = get_next_val(vector, i)\n",
    "        if(np.isnan(vector[i])):\n",
    "            if(np.isnan(prev_val)):\n",
    "                vector[i] = next_val\n",
    "            elif(np.isnan(next_val)):\n",
    "                vector[i] = prev_val\n",
    "            else:\n",
    "                temp = prev_val +  (next_val - prev_val)/ (nans + 1)\n",
    "                vector[i] = temp\n",
    "                prev_val = temp\n",
    "        else:\n",
    "            prev_val = vector[i]\n",
    "   return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_imputer(nds,method):\n",
    "    \"\"\"\n",
    "    Given a dataset removes NaNs using\n",
    "    Parameters:\n",
    "    Input nds - Numpy array: dataset\n",
    "    Input method - method of imputation to use\n",
    "    Output nds_xnan - Numpy array: dataset without NaNs\n",
    "    \"\"\"\n",
    "    if method==1:#Sklearn: IterativeImputer, removes NaN considering other features\n",
    "        imp = IterativeImputer(max_iter=100, random_state=0)\n",
    "        imp.fit(nds)\n",
    "        IterativeImputer(random_state=0)\n",
    "        nds_xnan = imp.transform(nds)\n",
    "    return nds_xnan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction functions\n",
    "1. time_reduction\n",
    "- flatten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_reduction(nds,labels, time, method):\n",
    "    \"\"\"\n",
    "    Given a dataset containing data on consecutive hours outputs a row extracting information time features\n",
    "    Parameters:\n",
    "    Input nds - numpy dataset\n",
    "    Input labels - list labels of dataset\n",
    "    Input time - time in hours to compress data \n",
    "    Input method - method of reduction to use\n",
    "    Output nds_reduced - dataset compressed \n",
    "    \"\"\"\n",
    "    nds = pd.DataFrame(nds,columns=labels)\n",
    "    datalen = len(nds)\n",
    "    numpat = int(datalen / time) #number of patients\n",
    "    \n",
    "    if method==1:#average of values per patient\n",
    "        #Reduce by taking mean of columns for each patient\n",
    "        nds_reduced = nds.groupby('pid',sort=False,as_index=False).mean()\n",
    "        \n",
    "    elif method==2:#scoring method based on evolution of patient during stay\n",
    "        dss = np.array_split(nds,numpat,axis=0) #dataset split for each patient  \n",
    "        nds_reduced = []\n",
    "        flagr=True\n",
    "        for k in range(numpat):#for each patient\n",
    "            patient = dss[k]#select patient\n",
    "            npat = patient.to_numpy()\n",
    "            r_pat = []\n",
    "            for i in range (np.size(npat,1)):#for each label\n",
    "                cur_col = npat[:,i]\n",
    "                temp=0\n",
    "                ev = 0\n",
    "                flagn = True\n",
    "                for j in range(np.size(cur_col)):#for each row\n",
    "                    this=cur_col[j]\n",
    "                    if ~(np.isnan(this)):\n",
    "                        ev = ev + ((this-temp)*(j+1)/10) #evolution increasing on time\n",
    "                        temp=this\n",
    "                        flagn= False\n",
    "                if flagn:#if row is all NaN\n",
    "                    r_pat = np.append(r_pat,np.NaN)#insert NaN\n",
    "                else:#else\n",
    "                    r_pat = np.append(r_pat,ev)#insert evolution\n",
    "            if flagr:#if reduced set is empty\n",
    "                nds_reduced = np.append(nds_reduced,r_pat)#insert patient\n",
    "                flagr=False\n",
    "            else:#if at least one patient has been added\n",
    "                nds_reduced = np.vstack((nds_reduced, r_pat))#insert patient as row\n",
    "        #Transform to pandas for compatibility\n",
    "        nds_reduced=pd.DataFrame(nds_reduced,columns=labels)\n",
    "    #Reduce considering patient evolution during stay \n",
    "    return nds_reduced.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining functions\n",
    "1. clean_set\n",
    "- flatten_min_max_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_set(nds,headers,imp_method,time_method,sequence):\n",
    "    \"\"\"\n",
    "    Given a dataset containing data on consecutive hours outputs a row extracting information time features\n",
    "    Parameters:\n",
    "    Input nds - numpy dataset\n",
    "    Input headers - list headers of dataset\n",
    "    Input imp_method - time in hours to compress data \n",
    "    Input time_method - method of reduction to use\n",
    "    Input sequence - method of reduction to use\n",
    "    Output  - dataset compressed \n",
    "    \"\"\"\n",
    "    ds_clean = nds\n",
    "    if sequence:\n",
    "        ds_clean = time_reduction(ds_clean, headers, 12,time_method)\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=headers)\n",
    "    else:\n",
    "        ds_clean = nan_imputer(ds_clean,imp_method)    \n",
    "        ds_clean = time_reduction(ds_clean, headers, 12,time_method)\n",
    "        ds_clean = pd.DataFrame(ds_clean, columns=headers)\n",
    "    \n",
    "        \n",
    "    return ds_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_min_max_slope(raw_data):\n",
    "    n,w =  raw_data.shape\n",
    "    c = w - 3\n",
    "    means = np.nanmean(raw_data,axis=0)\n",
    "    ndiv = int(n/12)\n",
    "    res = np.zeros((ndiv,1 + c * 3))\n",
    "    temp = np.zeros((12,c))\n",
    "    for i in range(ndiv):\n",
    "        temp = get_patient_matrix(raw_data,i)\n",
    "        for j in range (c):\n",
    "            temp[:,j] = interp(temp[:,j])\n",
    "        res[i][0] = raw_data[i * 12][2]\n",
    "        for j in range (c):\n",
    "            min = np.min(temp[:,j])\n",
    "            max = np.max(temp[:,j])\n",
    "            # if(min == 0):\n",
    "            #     min = means[j + 3]\n",
    "            # if(max == 0):\n",
    "            #     max = means[j + 3]\n",
    "            res[i][j*3+1] = min\n",
    "            res[i][j*3+2] = max\n",
    "            # res[i][j*3 + 2] = 0\n",
    "            res[i][j*3+3] = (max-min)/12\n",
    "    # print(res[0:5])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pca(raw_data):\n",
    "    n,w = raw_data.shape\n",
    "    c=w-3\n",
    "    ndiv = int(n/12)\n",
    "    res = np.zeros((ndiv,1 + c * 3))\n",
    "    temp = np.zeros((12,c))\n",
    "    for i in range(ndiv):\n",
    "        temp = get_patient_matrix(raw_data,i)\n",
    "        for j in range (c):\n",
    "            temp[:,j] = interp(temp[:,j])\n",
    "\n",
    "        res[i][0] = raw_data[i * 12][2] /100\n",
    "        # print(patient_pca(temp,c))\n",
    "        res[i][1:c*w-2] = patient_pca(temp,c)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choosing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fold_10(nds, f_nr, task):\n",
    "    \"\"\"\n",
    "    Given a dataset, outputs two subsets: training set and test set. Test sets is given by the f_nr-th partition of the dataset,\n",
    "    meanwhile the training set is the remaining of the dataset\n",
    "    Parameters:\n",
    "    Input ds - numpy dataset to partition\n",
    "    Input f_nr - number of the fold that will be the test set 1-10\n",
    "    Output (testset, trainingset) - tuple containing the test set and training set\n",
    "    \"\"\"\n",
    "    dss = np.array_split(nds,10,axis=0) #dataset split\n",
    "    testset = dss[f_nr] #test set\n",
    "    if task==2:\n",
    "        trainingset = np.hstack(np.delete(dss, f_nr, 0)) #training set \n",
    "    else:\n",
    "        trainingset = np.vstack(np.delete(dss, f_nr, 0)) #training set\n",
    "    return (testset, trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold10_predict(models, ndsx, ndsy, ndsy_L, task):\n",
    "    \"\"\"\n",
    "    Do 10 fold cross validation on training set for one of the three subtasks\n",
    "    Parameters:\n",
    "    Input models - list of models \n",
    "    Input ndsx - training features\n",
    "    Input ndsy - training labels\n",
    "    Input ndsy_L - training labels headers\n",
    "    Input task - subtask to fold\n",
    "    Output nscores - list containing the scores of each fold\n",
    "    \"\"\"\n",
    "    ###Performing 10-fold Cross Validation for each Model\n",
    "    mlen = len(models) #Number of models\n",
    "    nscores = np.zeros((mlen,10)) #score of each fold\n",
    "    for j in range(10):\n",
    "        #Creating test set and training set from data set \n",
    "        if task==2:\n",
    "            (tes_x, trs_x) = data_fold_10(ndsx, j, task-1)\n",
    "            (tes_y, trs_y) = data_fold_10(ndsy, j, task)\n",
    "        else:\n",
    "            (tes_x, trs_x) = data_fold_10(ndsx, j, task)\n",
    "            (tes_y, trs_y) = data_fold_10(ndsy, j, task)\n",
    "\n",
    "        #Perform fitting and predicting for each model\n",
    "        for i in range(mlen):\n",
    "            models[i].fit(trs_x,trs_y)\n",
    "            if task==3:#if task is third we use predict\n",
    "                tes_yp = models[i].predict(tes_x)\n",
    "\n",
    "                #Transform into DataFrame for scoring\n",
    "                df_y = pd.DataFrame(tes_y, columns=ndsy_L)\n",
    "                df_yp = pd.DataFrame(tes_yp, columns=ndsy_L)\n",
    "                nscores[i,j] = scores(df_y,df_yp, task)\n",
    "            else:\n",
    "                tes_yp = predict_sigmoid(models[i],tes_x)\n",
    "                #Transform into DataFrame for scoring\n",
    "                df_y = pd.DataFrame(tes_y, columns=ndsy_L)\n",
    "                if task==2:\n",
    "                    df_yp = pd.DataFrame(tes_yp, columns=ndsy_L)\n",
    "                else:\n",
    "                    df_yp = pd.DataFrame(tes_yp, columns=ndsy_L)\n",
    "                nscores[i,j] = scores(df_y,df_yp, task)\n",
    "    return nscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(tes_y, tes_yp, task):\n",
    "    \"\"\"\n",
    "    Give score for one of the subtask\n",
    "    Parameters:\n",
    "    Input tes_y - training labels\n",
    "    Input tes_yp - predicted labels\n",
    "    Input task - subtask\n",
    "    Output score - score of the subtask\n",
    "    \"\"\"\n",
    "    if task==3:\n",
    "        VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "        score = np.mean([0.5 + 0.5 * np.maximum(0, metrics.r2_score(tes_y[entry], tes_yp[entry])) for entry in VITALS])\n",
    "    elif task==2:\n",
    "        score = metrics.roc_auc_score(tes_y['LABEL_Sepsis'], tes_yp['LABEL_Sepsis'])\n",
    "    else:\n",
    "        TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "        score = np.mean([metrics.roc_auc_score(tes_y[entry], tes_yp[entry]) for entry in TESTS])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sigmoid(X):\n",
    "    xshape = X.shape\n",
    "    if len(xshape)==1:\n",
    "        n = xshape[0]\n",
    "        for i in range(n):\n",
    "            X[i] = sigmoid(X[i])\n",
    "    else:\n",
    "        n,m = xshape\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                X[i][j] = sigmoid(X[i][j])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sigmoid(clf,data):\n",
    "    return map_sigmoid(clf.decision_function(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_scaler(scal,dataset):\n",
    "    \"\"\"\n",
    "    Give score for one of the subtask\n",
    "    Parameters:\n",
    "    Input scaler - scaler to fit\n",
    "    Input data - data \n",
    "    Output fit_scaler - scaler fitted on data\n",
    "    \"\"\"\n",
    "    return scal.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup datasets and scalers for all subtasks\n",
    "\n",
    "#Extracting training labels and features\n",
    "dataset_y = pd.read_csv(\"train_labels.csv\")\n",
    "dataset_x = pd.read_csv(\"train_features.csv\")\n",
    "\n",
    "#lists that contain header of dataset\n",
    "dataset_x_L = list(dataset_x)\n",
    "\n",
    "#Clean set\n",
    "cds = clean_set(dataset_x,dataset_x_L,1,1,True)\n",
    "\n",
    "#Matt dataset\n",
    "raw_data = np.genfromtxt(\"./train_features.csv\",delimiter=\",\",skip_header=1)\n",
    "mdata = flatten_min_max_slope(raw_data)\n",
    "\n",
    "#Prepare all scalers \n",
    "scds = StandardScaler()\n",
    "scds.fit(cds)\n",
    "mmcds = MinMaxScaler()\n",
    "mmcds.fit(cds)\n",
    "rcds = RobustScaler()\n",
    "rcds.fit(cds)\n",
    "ncds = Normalizer()\n",
    "\n",
    "sm = StandardScaler()\n",
    "sm.fit(mdata)\n",
    "mmm = MinMaxScaler()\n",
    "mmm.fit(mdata)\n",
    "rm = RobustScaler()\n",
    "rm.fit(mdata)\n",
    "\n",
    "#Training Labels\n",
    "#Subtask1\n",
    "dataset_y1 = dataset_y.loc[:,\"LABEL_BaseExcess\":\"LABEL_EtCO2\"] #Labels to be predicted in [0,1] range\n",
    "ds_y1_L = list(dataset_y1) #headers of labels\n",
    "ndsy1 = dataset_y1.to_numpy() #to numpy\n",
    "\n",
    "#Subtask2\n",
    "dataset_y2 = dataset_y.loc[:,\"LABEL_Sepsis\"] #Labels to be predicted in [0,1] range\n",
    "ds_y2_L = [\"LABEL_Sepsis\"] #headers of labels\n",
    "ndsy2 = dataset_y2.to_numpy() #to numpy\n",
    "\n",
    "#Subtask3\n",
    "dataset_y3 = dataset_y.loc[:,\"LABEL_RRate\":\"LABEL_Heartrate\"] #Labels to be predicted\n",
    "ds_y3_L = list(dataset_y3) #headers of labels\n",
    "ndsy3 = dataset_y3.to_numpy() #to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask1 training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtask 1\n",
    "#Training Features\n",
    "#Scale dataset, options: StandardScaler, MinMaxScaler and RobustScaler\n",
    "#sds_p1 = pd.DataFrame(scds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p1 = pd.DataFrame(mmcds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p1 =pd.DataFrame(rcds.transform(cds),columns=dataset_x_L)\n",
    "sds_p1 =pd.DataFrame(ncds.transform(cds),columns=dataset_x_L)\n",
    "\n",
    "##Division for the prediction, probabilities divided from the real values\n",
    "ds_p1 = sds_p1.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "#labels of datasets\n",
    "ds_p1_L = list(ds_p1)\n",
    "#transform into numpy\n",
    "nds_p1 = ds_p1.to_numpy()\n",
    "\n",
    "\n",
    "# Matts datasets: options: StandardScaler,MinMaxScaler and RobustScaler\n",
    "mnds_p1 = sm.transform(mdata)\n",
    "#mnds_p1 = mmm.transform(mdata)\n",
    "#mnds_p1 = rm.transform(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model set used for training\n",
    "lsvc_m1 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                dual=False, \n",
    "                                tol=0.00001,\n",
    "                                C=5,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )\n",
    "lsvc_m2 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                penalty='l1',\n",
    "                                loss = 'squared_hinge',\n",
    "                                C=0.019,\n",
    "                                dual=False, \n",
    "                                tol=0.001,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )\n",
    "\n",
    "matt_svcms = svm.SVC(kernel='rbf',\n",
    "                     decision_function_shape='ovr', \n",
    "                     C=0.6,\n",
    "                     max_iter=10000000,\n",
    "                     gamma='auto'\n",
    "                    )\n",
    "models1 = []\n",
    "#0 - Sklearn: OnveVsRestClassifier using svcms\n",
    "#models1 = np.append(models1,OneVsRestClassifier(svcms))\n",
    "#1 - Sklearn: OnveVsRestClassifier using lvsc_m3\n",
    "models1 = np.append(models1,OneVsRestClassifier(lsvc_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.801225</td>\n",
       "      <td>0.811822</td>\n",
       "      <td>0.809428</td>\n",
       "      <td>0.795182</td>\n",
       "      <td>0.79823</td>\n",
       "      <td>0.78475</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>0.791643</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>0.80482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3        4        5         6  \\\n",
       "0  0.801225  0.811822  0.809428  0.795182  0.79823  0.78475  0.800129   \n",
       "\n",
       "          7         8        9  \n",
       "0  0.791643  0.796676  0.80482  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Predictions\n",
    "s1 = fold10_predict(models1,mnds_p1,ndsy1,ds_y1_L,1)\n",
    "pd.DataFrame(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.79939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0  0.79939"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_s1 = np.average(s1,axis=1)\n",
    "pd.DataFrame(avg_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79939])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask2 - training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtask 2\n",
    "#Training Features\n",
    "sds_p2 = pd.DataFrame(scds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p2 = pd.DataFrame(mmcds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p2 =pd.DataFrame(rcds.transform(cds),columns=dataset_x_L)\n",
    "\n",
    "ds_p2 = sds_p2.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "ds_p2_L = list(ds_p2)\n",
    "nds_p2 = ds_p2.to_numpy()\n",
    "\n",
    "# Matts datasets\n",
    "mnds_p2 = sm.transform(mdata)\n",
    "#mnds_p2 = mmm.transform(mdata)\n",
    "#mnds_p2 = rm.transform(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model list used for predictions\n",
    "models2 = []\n",
    "##mattds, 0.07\n",
    "\n",
    "svc_m0 = sklearn.svm.SVC(C=0.0019, \n",
    "                         kernel='rbf',\n",
    "                         degree=3,\n",
    "                         gamma='scale',\n",
    "                         coef0=0.0,\n",
    "                         shrinking=True,\n",
    "                         probability=False,\n",
    "                         tol=0.001,\n",
    "                         cache_size=200,\n",
    "                         class_weight=None,\n",
    "                         verbose=False, \n",
    "                         max_iter=-1,\n",
    "                         decision_function_shape='ovr', \n",
    "                         random_state=None)\n",
    "\n",
    "lsvc_m1 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                penalty='l2',\n",
    "                                loss = 'squared_hinge',\n",
    "                                C=0.0019,\n",
    "                                dual=False, \n",
    "                                tol=0.001,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )\n",
    "\n",
    "\n",
    "#1 - Sklearn: SVR\n",
    "#models2 = np.append(models2,matt_svcms)\n",
    "#from sklearn.svm import LinearSVC\n",
    "models2 = np.append(models2,lsvc_m1)\n",
    "#models2 = np.append(models2,svc_m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "s2 = fold10_predict(models2,mnds_p2,ndsy2,ds_y2_L,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.658998</td>\n",
       "      <td>0.715432</td>\n",
       "      <td>0.725145</td>\n",
       "      <td>0.688129</td>\n",
       "      <td>0.736282</td>\n",
       "      <td>0.712471</td>\n",
       "      <td>0.733558</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.691423</td>\n",
       "      <td>0.684032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.658998  0.715432  0.725145  0.688129  0.736282  0.712471  0.733558   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.742257  0.691423  0.684032  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.708773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.708773"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_s2 = np.average(s2,axis=1)\n",
    "pd.DataFrame(avg_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current best, matt's standard and \n",
    "lsvc_m1 = sklearn.svm.LinearSVC(random_state=0,\n",
    "                                penalty='l1',\n",
    "                                loss = 'squared_hinge',\n",
    "                                C=0.019,\n",
    "                                dual=False, \n",
    "                                tol=0.001,\n",
    "                                max_iter=100000,\n",
    "                                fit_intercept=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask3 - training models\n",
    "I included only ridge as it is relatively fast and produces ~0.745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtask 3\n",
    "#Training Features\n",
    "#sds_p3 = pd.DataFrame(scds.transform(cds),columns=dataset_x_L)\n",
    "sds_p3 = pd.DataFrame(mmcds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p3 =pd.DataFrame(rcds.transform(cds),columns=dataset_x_L)\n",
    "#sds_p3 =pd.DataFrame(ncds.transform(cds),columns=dataset_x_L)\n",
    "\n",
    "ds_p3 = sds_p3.loc[:,\"Time\":\"pH\"] #reduced dataset for prediction, without pid\n",
    "ds_p3_L = list(ds_p3)\n",
    "nds_p3 = ds_p3.to_numpy()\n",
    "\n",
    "# Matts datasets\n",
    "mnds_p3 = sm.transform(mdata)\n",
    "#mnds_p3 = mmm.transform(mdata)\n",
    "#mnds_p3 = rm.transform(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "\n",
    "rm0 = sklearn.linear_model.Ridge(alpha=0.112,\n",
    "                                      fit_intercept=True,\n",
    "                                      normalize=False, \n",
    "                                      copy_X=True,\n",
    "                                      max_iter=100000,\n",
    "                                      tol=1e-6,\n",
    "                                      solver='auto',\n",
    "                                      random_state=None\n",
    "                                     )\n",
    "\n",
    "\n",
    "\n",
    "lm0 = sklearn.linear_model.Lasso(alpha=0.0001,\n",
    "                                      fit_intercept=True, \n",
    "                                      normalize=True, \n",
    "                                      precompute=True, \n",
    "                                      copy_X=True, \n",
    "                                      max_iter=10000000, \n",
    "                                      tol=0.0001, \n",
    "                                      warm_start=False, \n",
    "                                      positive=True, \n",
    "                                      random_state=None, \n",
    "                                      selection='random')\n",
    "\n",
    "\n",
    "\n",
    "rcv = sklearn.linear_model.RidgeCV(alphas=[0 + 0.001*a for a in range(1,100)],\n",
    "                                   fit_intercept=True, \n",
    "                                   normalize=False,\n",
    "                                   scoring=None,\n",
    "                                   cv=None,\n",
    "                                   gcv_mode=None,\n",
    "                                   store_cv_values=False\n",
    "                                  )\n",
    "\n",
    "lcv = sklearn.linear_model.LassoCV(eps=0.001,\n",
    "                                   n_alphas=100,\n",
    "                                   alphas=None,\n",
    "                                   fit_intercept=True,\n",
    "                                   normalize=True, \n",
    "                                   precompute='auto',\n",
    "                                   max_iter=1000, \n",
    "                                   tol=0.0001,\n",
    "                                   copy_X=True,\n",
    "                                   cv=5, \n",
    "                                   verbose=False,\n",
    "                                   n_jobs=None,\n",
    "                                   positive=False,\n",
    "                                   random_state=None, \n",
    "                                   selection='cyclic'\n",
    "                                  )\n",
    "\n",
    "mlcv = sklearn.linear_model.MultiTaskLassoCV(eps=0.001,\n",
    "                                            n_alphas=1000,\n",
    "                                            alphas=None,\n",
    "                                            fit_intercept=True,\n",
    "                                            normalize=True,\n",
    "                                            max_iter=1000, \n",
    "                                            tol=0.0001, \n",
    "                                            copy_X=True,\n",
    "                                            cv=5, \n",
    "                                            verbose=False,\n",
    "                                            n_jobs=None, \n",
    "                                            random_state=None, \n",
    "                                            selection='cyclic'\n",
    "                                           )\n",
    "##Model set used for training\n",
    "models3 = []\n",
    "#0 - Sklearn: Ridge regression function with alpha 1\n",
    "models3 = np.append(models3, MultiOutputRegressor(rm0)) \n",
    "#models3 = np.append(models3, rcv) \n",
    "#models3 = np.append(models3, mlcv)\n",
    "#models3 = np.append(models3, lm0) \n",
    "#models3 = np.append(models3, lm1)\n",
    "#1 Sklearn: Multitask Elastic Net with Cross Validation\n",
    "#models3 = np.append(models3,mtencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "s3 = fold10_predict(models3, nds_p3, ndsy3, ds_y3_L, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.749344</td>\n",
       "      <td>0.746425</td>\n",
       "      <td>0.740742</td>\n",
       "      <td>0.744761</td>\n",
       "      <td>0.732403</td>\n",
       "      <td>0.767885</td>\n",
       "      <td>0.743762</td>\n",
       "      <td>0.732367</td>\n",
       "      <td>0.749157</td>\n",
       "      <td>0.754903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.749344  0.746425  0.740742  0.744761  0.732403  0.767885  0.743762   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.732367  0.749157  0.754903  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.746175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.746175"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_s3 = np.average(s3,axis=1)\n",
    "pd.DataFrame(avg_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset prediction - in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy code to combine three results\n",
    "best_1 = models1[0]#Dummy\n",
    "best_2 = models2[0]#Dummy\n",
    "best_3 = models3[0]#Dummy\n",
    "\n",
    "#training best model on entire dataset\n",
    "best_1.fit(mnds_p1,ndsy1)\n",
    "best_2.fit(mnds_p2,ndsy2)\n",
    "best_3.fit(nds_p3,ndsy3)\n",
    "\n",
    "#extract dataset to predict\n",
    "testset_x = pd.read_csv(\"test_features.csv\")\n",
    "testset_x_L = list(testset_x)\n",
    "test_x = testset_x.to_numpy()\n",
    "\n",
    "test_raw = np.genfromtxt(\"./test_features.csv\",delimiter=\",\",skip_header=1)\n",
    "\n",
    "#cleaning data\n",
    "test12_x = flatten_min_max_slope(test_raw)\n",
    "test3_x = clean_set(testset_x,testset_x_L,1,1,True)\n",
    "\n",
    "#scale data\n",
    "test12_x = sm.transform(test12_x)\n",
    "test3_x = pd.DataFrame(mmcds.transform(test3_x),columns=dataset_x_L)\n",
    "\n",
    "#reduced dataset for prediction, without pid\n",
    "#ctes1 = test1_x.loc[:,\"Time\":\"pH\"] \n",
    "#ctes2 = test2_x.loc[:,\"Time\":\"pH\"]\n",
    "ctes3 = test3_x.loc[:,\"Time\":\"pH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction using best models for each subtask\n",
    "pred1 = predict_sigmoid(best_1,test12_x)\n",
    "pred2 = predict_sigmoid(best_2,test12_x)\n",
    "pred3 = best_3.predict(ctes3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion to df\n",
    "pred1 = pd.DataFrame(pred1,columns=ds_y1_L)\n",
    "pred2 = pd.DataFrame(pred2,columns=ds_y2_L)\n",
    "pred3 = pd.DataFrame(pred3,columns=ds_y3_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707593</td>\n",
       "      <td>0.654844</td>\n",
       "      <td>0.993288</td>\n",
       "      <td>0.985365</td>\n",
       "      <td>0.991291</td>\n",
       "      <td>0.486329</td>\n",
       "      <td>0.242553</td>\n",
       "      <td>0.337295</td>\n",
       "      <td>0.372765</td>\n",
       "      <td>0.270237</td>\n",
       "      <td>0.342013</td>\n",
       "      <td>14.012866</td>\n",
       "      <td>83.416372</td>\n",
       "      <td>98.748881</td>\n",
       "      <td>82.715085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.329964</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.398904</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>0.398920</td>\n",
       "      <td>0.320671</td>\n",
       "      <td>0.325067</td>\n",
       "      <td>0.315605</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.277493</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>18.266961</td>\n",
       "      <td>88.308131</td>\n",
       "      <td>94.943706</td>\n",
       "      <td>102.685540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10003</td>\n",
       "      <td>0.387979</td>\n",
       "      <td>0.280745</td>\n",
       "      <td>0.343495</td>\n",
       "      <td>0.345677</td>\n",
       "      <td>0.347167</td>\n",
       "      <td>0.368191</td>\n",
       "      <td>0.297728</td>\n",
       "      <td>0.490090</td>\n",
       "      <td>0.285779</td>\n",
       "      <td>0.287705</td>\n",
       "      <td>0.277381</td>\n",
       "      <td>18.828149</td>\n",
       "      <td>81.412713</td>\n",
       "      <td>97.769234</td>\n",
       "      <td>92.562836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10004</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>0.286903</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.410492</td>\n",
       "      <td>0.405745</td>\n",
       "      <td>0.298992</td>\n",
       "      <td>0.316362</td>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.284264</td>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.280757</td>\n",
       "      <td>16.559621</td>\n",
       "      <td>72.310694</td>\n",
       "      <td>95.809019</td>\n",
       "      <td>88.179003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10005</td>\n",
       "      <td>0.339288</td>\n",
       "      <td>0.274910</td>\n",
       "      <td>0.297833</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>0.300466</td>\n",
       "      <td>0.305847</td>\n",
       "      <td>0.286129</td>\n",
       "      <td>0.313274</td>\n",
       "      <td>0.269874</td>\n",
       "      <td>0.231511</td>\n",
       "      <td>0.288193</td>\n",
       "      <td>19.385573</td>\n",
       "      <td>74.566437</td>\n",
       "      <td>95.965975</td>\n",
       "      <td>61.564921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12659</td>\n",
       "      <td>9989</td>\n",
       "      <td>0.484036</td>\n",
       "      <td>0.282942</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>0.356410</td>\n",
       "      <td>0.354223</td>\n",
       "      <td>0.418644</td>\n",
       "      <td>0.232480</td>\n",
       "      <td>0.363094</td>\n",
       "      <td>0.272366</td>\n",
       "      <td>0.227755</td>\n",
       "      <td>0.330300</td>\n",
       "      <td>19.751896</td>\n",
       "      <td>79.975079</td>\n",
       "      <td>95.726405</td>\n",
       "      <td>103.082205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12660</td>\n",
       "      <td>9991</td>\n",
       "      <td>0.515473</td>\n",
       "      <td>0.329618</td>\n",
       "      <td>0.376097</td>\n",
       "      <td>0.355090</td>\n",
       "      <td>0.359779</td>\n",
       "      <td>0.407493</td>\n",
       "      <td>0.256220</td>\n",
       "      <td>0.250685</td>\n",
       "      <td>0.266227</td>\n",
       "      <td>0.295365</td>\n",
       "      <td>0.318244</td>\n",
       "      <td>18.190472</td>\n",
       "      <td>95.584866</td>\n",
       "      <td>98.851082</td>\n",
       "      <td>74.358144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12661</td>\n",
       "      <td>9992</td>\n",
       "      <td>0.507762</td>\n",
       "      <td>0.289909</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>0.320365</td>\n",
       "      <td>0.323363</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.250529</td>\n",
       "      <td>0.517562</td>\n",
       "      <td>0.275168</td>\n",
       "      <td>0.262315</td>\n",
       "      <td>0.286965</td>\n",
       "      <td>18.762833</td>\n",
       "      <td>69.064481</td>\n",
       "      <td>97.343220</td>\n",
       "      <td>84.219772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12662</td>\n",
       "      <td>9994</td>\n",
       "      <td>0.930942</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.698526</td>\n",
       "      <td>0.739675</td>\n",
       "      <td>0.789949</td>\n",
       "      <td>0.889366</td>\n",
       "      <td>0.197899</td>\n",
       "      <td>0.791365</td>\n",
       "      <td>0.313319</td>\n",
       "      <td>0.240242</td>\n",
       "      <td>0.421104</td>\n",
       "      <td>15.934689</td>\n",
       "      <td>86.604429</td>\n",
       "      <td>98.528002</td>\n",
       "      <td>96.415236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12663</td>\n",
       "      <td>9997</td>\n",
       "      <td>0.648137</td>\n",
       "      <td>0.271480</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.314275</td>\n",
       "      <td>0.318412</td>\n",
       "      <td>0.397639</td>\n",
       "      <td>0.264845</td>\n",
       "      <td>0.348192</td>\n",
       "      <td>0.266487</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.310522</td>\n",
       "      <td>18.170226</td>\n",
       "      <td>77.545852</td>\n",
       "      <td>98.240598</td>\n",
       "      <td>85.896066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.707593          0.654844   0.993288   \n",
       "1      10001          0.329964          0.289032   0.398904   \n",
       "2      10003          0.387979          0.280745   0.343495   \n",
       "3      10004          0.263019          0.286903   0.410673   \n",
       "4      10005          0.339288          0.274910   0.297833   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989          0.484036          0.282942   0.362074   \n",
       "12660   9991          0.515473          0.329618   0.376097   \n",
       "12661   9992          0.507762          0.289909   0.325219   \n",
       "12662   9994          0.930942          0.569146   0.698526   \n",
       "12663   9997          0.648137          0.271480   0.320050   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.985365               0.991291       0.486329   \n",
       "1                0.398247               0.398920       0.320671   \n",
       "2                0.345677               0.347167       0.368191   \n",
       "3                0.410492               0.405745       0.298992   \n",
       "4                0.294815               0.300466       0.305847   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.356410               0.354223       0.418644   \n",
       "12660            0.355090               0.359779       0.407493   \n",
       "12661            0.320365               0.323363       0.366714   \n",
       "12662            0.739675               0.789949       0.889366   \n",
       "12663            0.314275               0.318412       0.397639   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.242553    0.337295                0.372765     0.270237   \n",
       "1             0.325067    0.315605                0.279186     0.277493   \n",
       "2             0.297728    0.490090                0.285779     0.287705   \n",
       "3             0.316362    0.299407                0.284264     0.290991   \n",
       "4             0.286129    0.313274                0.269874     0.231511   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.232480    0.363094                0.272366     0.227755   \n",
       "12660         0.256220    0.250685                0.266227     0.295365   \n",
       "12661         0.250529    0.517562                0.275168     0.262315   \n",
       "12662         0.197899    0.791365                0.313319     0.240242   \n",
       "12663         0.264845    0.348192                0.266487     0.238938   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0          0.342013    14.012866   83.416372   98.748881        82.715085  \n",
       "1          0.285905    18.266961   88.308131   94.943706       102.685540  \n",
       "2          0.277381    18.828149   81.412713   97.769234        92.562836  \n",
       "3          0.280757    16.559621   72.310694   95.809019        88.179003  \n",
       "4          0.288193    19.385573   74.566437   95.965975        61.564921  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659      0.330300    19.751896   79.975079   95.726405       103.082205  \n",
       "12660      0.318244    18.190472   95.584866   98.851082        74.358144  \n",
       "12661      0.286965    18.762833   69.064481   97.343220        84.219772  \n",
       "12662      0.421104    15.934689   86.604429   98.528002        96.415236  \n",
       "12663      0.310522    18.170226   77.545852   98.240598        85.896066  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the pids and assemble final prediction\n",
    "pids = time_reduction(testset_x,list(testset_x),12,1)\n",
    "pd.DataFrame(pids)\n",
    "pids = pd.DataFrame(pids[:,0],columns=['pid'])\n",
    "pred = pd.concat([pids.astype(int),pred1,pred2, pred3], axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine predictions into one dataframe\n",
    "#output, 3 digit floats\n",
    "pred.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check format\n",
    "df_submission = pd.read_csv('prediction.zip')\n",
    "df_sample = pd.read_csv('sample.zip')\n",
    "df_submission.shape == df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.341</td>\n",
       "      <td>12.008</td>\n",
       "      <td>80.057</td>\n",
       "      <td>98.734</td>\n",
       "      <td>82.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.288</td>\n",
       "      <td>18.145</td>\n",
       "      <td>88.704</td>\n",
       "      <td>94.911</td>\n",
       "      <td>102.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10003</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.279</td>\n",
       "      <td>18.151</td>\n",
       "      <td>83.593</td>\n",
       "      <td>97.850</td>\n",
       "      <td>91.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10004</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.284</td>\n",
       "      <td>16.794</td>\n",
       "      <td>72.866</td>\n",
       "      <td>95.782</td>\n",
       "      <td>88.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10005</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.291</td>\n",
       "      <td>20.202</td>\n",
       "      <td>75.970</td>\n",
       "      <td>95.932</td>\n",
       "      <td>61.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12659</td>\n",
       "      <td>9989</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.334</td>\n",
       "      <td>19.832</td>\n",
       "      <td>80.770</td>\n",
       "      <td>95.694</td>\n",
       "      <td>103.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12660</td>\n",
       "      <td>9991</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.321</td>\n",
       "      <td>16.405</td>\n",
       "      <td>92.036</td>\n",
       "      <td>98.821</td>\n",
       "      <td>74.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12661</td>\n",
       "      <td>9992</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.289</td>\n",
       "      <td>19.432</td>\n",
       "      <td>71.552</td>\n",
       "      <td>97.368</td>\n",
       "      <td>84.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12662</td>\n",
       "      <td>9994</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.425</td>\n",
       "      <td>15.256</td>\n",
       "      <td>85.095</td>\n",
       "      <td>98.470</td>\n",
       "      <td>96.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12663</td>\n",
       "      <td>9997</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.312</td>\n",
       "      <td>18.295</td>\n",
       "      <td>75.711</td>\n",
       "      <td>98.183</td>\n",
       "      <td>86.809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0             0.542             0.485      0.596   \n",
       "1      10001             0.261             0.267      0.270   \n",
       "2      10003             0.257             0.270      0.255   \n",
       "3      10004             0.259             0.261      0.248   \n",
       "4      10005             0.230             0.260      0.251   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989             0.560             0.276      0.274   \n",
       "12660   9991             0.460             0.317      0.393   \n",
       "12661   9992             0.434             0.275      0.259   \n",
       "12662   9994             0.497             0.406      0.524   \n",
       "12663   9997             0.770             0.259      0.238   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                   0.599                  0.602          0.436   \n",
       "1                   0.270                  0.270          0.268   \n",
       "2                   0.258                  0.261          0.220   \n",
       "3                   0.247                  0.246          0.267   \n",
       "4                   0.251                  0.257          0.256   \n",
       "...                   ...                    ...            ...   \n",
       "12659               0.279                  0.276          0.306   \n",
       "12660               0.384                  0.389          0.377   \n",
       "12661               0.261                  0.263          0.287   \n",
       "12662               0.527                  0.533          0.511   \n",
       "12663               0.235                  0.236          0.312   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0                0.294       0.409                   0.308        0.300   \n",
       "1                0.267       0.265                   0.269        0.268   \n",
       "2                0.267       0.305                   0.266        0.236   \n",
       "3                0.263       0.275                   0.263        0.267   \n",
       "4                0.253       0.249                   0.264        0.217   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659            0.238       0.292                   0.269        0.242   \n",
       "12660            0.278       0.349                   0.272        0.280   \n",
       "12661            0.249       0.631                   0.266        0.260   \n",
       "12662            0.304       0.451                   0.311        0.315   \n",
       "12663            0.263       0.265                   0.264        0.174   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0             0.341       12.008      80.057      98.734           82.152  \n",
       "1             0.288       18.145      88.704      94.911          102.911  \n",
       "2             0.279       18.151      83.593      97.850           91.324  \n",
       "3             0.284       16.794      72.866      95.782           88.420  \n",
       "4             0.291       20.202      75.970      95.932           61.871  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659         0.334       19.832      80.770      95.694          103.481  \n",
       "12660         0.321       16.405      92.036      98.821           74.250  \n",
       "12661         0.289       19.432      71.552      97.368           84.167  \n",
       "12662         0.425       15.256      85.095      98.470           96.872  \n",
       "12663         0.312       18.295      75.711      98.183           86.809  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sol = pd.read_csv('./predictions/0.74/prediction.zip')\n",
    "last_sol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
