{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import PIL\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "## To Setup project:\n",
    "### have test_triplets and train_triplets in ./data/\n",
    "### have all images  in jpeg in ./data/food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup image dict, pretrained vgg16 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_triplets():\n",
    "    return np.genfromtxt(\"./data/train_triplets.txt\", dtype=\"str\")\n",
    "\n",
    "\n",
    "def get_test_triplets():\n",
    "    return np.genfromtxt(\"./data/test_triplets.txt\", dtype=\"str\")\n",
    "\n",
    "def get_image_path(name):\n",
    "    return './data/food/' + name + '.jpg'\n",
    "\n",
    "\n",
    "# Here we use VGG16 pretrained deep CNN to extract features from Images\n",
    "# TODO: Increase accuracy by training the model on our dataset?\n",
    "def setup_pretrained_model():\n",
    "    #Decisions:\n",
    "        # - max or avg?\n",
    "    model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def feature_extraction(model,name):\n",
    "    img = image.load_img(get_image_path(name),target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model.predict(x)[0] ##[0] to change shape from (1,512) -> (512, )\n",
    "\n",
    "\n",
    "def append(arr1,arr2):\n",
    "    m = arr1.size\n",
    "    n = arr2.size\n",
    "    res = np.zeros(m + n)\n",
    "    res[0:m] = arr1\n",
    "    res[m:m + n] = arr2\n",
    "    return res\n",
    "\n",
    "def create_dict(model):\n",
    "    triplets1 = get_train_triplets()\n",
    "    triplets2 = get_test_triplets()\n",
    "    strings1 = np.reshape(triplets1,(triplets1.size))\n",
    "    strings2 = np.reshape(triplets2,(triplets2.size))\n",
    "    for name in strings1:\n",
    "        if(name not in DICT):\n",
    "            DICT[name]  =  feature_extraction(model,name)\n",
    "    for name in strings2:\n",
    "        if(name not in DICT):\n",
    "            DICT[name]  =  feature_extraction(model,name)\n",
    "\n",
    "def get_feature(name):\n",
    "    return DICT[name]\n",
    "\n",
    "\n",
    "\n",
    "def setup_data(model,min,max,train):\n",
    "    if(train):\n",
    "        triplets = get_train_triplets()\n",
    "    else:\n",
    "        triplets = get_test_triplets()\n",
    "    m,n = triplets.shape\n",
    "    res = np.zeros((2 * m, 1024))\n",
    "    labels = np.zeros(2 * m)\n",
    "    for i in range(m):\n",
    "        anchor = get_feature(triplets[i][0])\n",
    "        pos = get_feature(triplets[i][1])\n",
    "        neg = get_feature(triplets[i][2])\n",
    "        res[2 * i ][0:512] = anchor\n",
    "        res[2 * i ][512:1024] = pos\n",
    "\n",
    "        res[2 * i + 1][0:512] = anchor\n",
    "        res[2 * i + 1][512:1024] = neg\n",
    "\n",
    "        labels[2 * i] = 1\n",
    "        labels[2 * i + 1] = 0\n",
    "    return res,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connect model (approximating the distance function of similiarities between two images based on extracted features and human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fully_connect_model():\n",
    "    inputs = keras.Input(shape=(1024,))\n",
    "    x = layers.Dense(256,activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(256,activation=\"relu\")(x)\n",
    "    x = layers.Dense(64,activation=\"relu\")(x)\n",
    "    x = layers.Dense(64,activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs,outputs=outputs,name=\"fully_connected\")\n",
    "    return model\n",
    "\n",
    "def parse_results(results):\n",
    "    n = math.floor(results.size /2)\n",
    "    ret = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if(results[i * 2] > results[i * 2 + 1]):\n",
    "            ret[i] = 1\n",
    "        else:\n",
    "            ret[i] = 0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02461' '03450' '02678' ... '02509' '02552' '03406']\n",
      "['09896' '09640' '09177' ... '08475' '06082' '09044']\n"
     ]
    }
   ],
   "source": [
    "DICT = {}\n",
    "def dict():\n",
    "    pretrained_model = setup_pretrained_model()\n",
    "    create_dict(pretrained_model)\n",
    "dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119030 samples\n",
      "119030/119030 [==============================] - 16s 137us/sample - loss: 0.6406 - accuracy: 0.6267\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pretrained_model = setup_pretrained_model()\n",
    "    fully_connected_model = create_fully_connect_model()\n",
    "    fully_connected_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    train_data,labels = setup_data(pretrained_model,0,5000,True)\n",
    "    fully_connected_model.fit(train_data,labels)\n",
    "    \n",
    "    test_data, labels = setup_data(pretrained_model,0,0,False)\n",
    "    \n",
    "    results = fully_connected_model.predict(test_data)\n",
    "    output = parse_results(results)\n",
    "    np.savetxt('testing.txt',results,fmt='%.18e')\n",
    "    np.savetxt('submission.txt',output,fmt='%d')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
